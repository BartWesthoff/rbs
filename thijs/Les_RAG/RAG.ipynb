{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install required libraries and Import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "# !pip install wikipedia rank-bm25 transformers numpy tiktoken     ## uncomment if running in a new environment\n",
    "\n",
    "# Import necessary libraries\n",
    "import wikipedia\n",
    "from rank_bm25 import BM25Okapi\n",
    "from transformers import pipeline\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetch and preprocess Simple Wikipedia articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 366 paragraphs from 5 articles.\n"
     ]
    }
   ],
   "source": [
    "def fetch_and_split_articles(titles):\n",
    "    # https://meta.wikimedia.org/wiki/List_of_Wikipedias\n",
    "    wikipedia.set_lang(\"en\")  # Use English Wikipedia by default\n",
    "    paragraphs = []\n",
    "    for title in titles:\n",
    "        try:\n",
    "            page = wikipedia.page(title, auto_suggest=False)\n",
    "            content = page.content\n",
    "            # Split into paragraphs (separated by double newlines)\n",
    "            paras = content.split('\\n\\n')\n",
    "            paragraphs.extend([para.strip() for para in paras if para.strip()])\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch {title}: {e}\")\n",
    "    return paragraphs\n",
    "\n",
    "# List of article titles for the demo\n",
    "titles = ['Dog', 'Moon', 'Computer', 'Solar System', 'Animals']\n",
    "paragraphs = fetch_and_split_articles(titles)\n",
    "print(f\"Collected {len(paragraphs)} paragraphs from {len(titles)} articles.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up BM25 retriever & Load the question-answering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Tokenize paragraphs (split into words)\n",
    "tokenized_paragraphs = [para.lower().split() for para in paragraphs]\n",
    "bm25 = BM25Okapi(tokenized_paragraphs)\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run example queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAG System Demo ===\n",
      "\n",
      "**Query**: How long have humans and dogs been together?\n",
      "**Retrieved Paragraph**: There are around 450 official dog breeds, the most of any mammal. Dogs began diversifying in the Victorian era, when humans took control of their natural selection. Most breeds were derived from small...\n",
      "--------------------------------------------------\n",
      "\n",
      "**Query**: How many planets are in our solar system?\n",
      "**Retrieved Paragraph**: Besides solar energy, the primary characteristic of the Solar System enabling the presence of life is the heliosphere and planetary magnetic fields (for those planets that have them). These magnetic f...\n",
      "--------------------------------------------------\n",
      "\n",
      "**Query**: Who invented the computer?\n",
      "**Retrieved Paragraph**: The Antikythera mechanism is believed to be the earliest known mechanical analog computer, according to Derek J. de Solla Price. It was designed to calculate astronomical positions. It was discovered ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to process a query\n",
    "def process_query(query):\n",
    "    # Tokenize the query\n",
    "    query_tokens = query.lower().split()\n",
    "    # Get relevance scores for all paragraphs\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    # Find the most relevant paragraph\n",
    "    top_idx = np.argmax(scores)\n",
    "    retrieved_para = paragraphs[top_idx]\n",
    "    # Extract the answer from the retrieved paragraph\n",
    "    answer = qa_pipeline(question=query, context=retrieved_para)\n",
    "    return retrieved_para, answer['answer']\n",
    "\n",
    "# Run example queries for the showcase\n",
    "if __name__ == \"__main__\":\n",
    "    example_queries = [\n",
    "        \"How long have humans and dogs been together?\",\n",
    "        \"How many planets are in our solar system?\",\n",
    "        \"Who invented the computer?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=== RAG System Demo ===\")\n",
    "    for query in example_queries:\n",
    "        retrieved_para, answer = process_query(query)\n",
    "        print(f\"\\n**Query**: {query}\")\n",
    "        print(f\"**Retrieved Paragraph**: {retrieved_para[:200]}...\")  # Show first 200 characters\n",
    "        # print(f\"**Answer**: {answer}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
